{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network Implementation on SPI for Drought Prediction\n",
    "\n",
    "Objective:\n",
    "\n",
    "-  To predict the Standardized Precipitation Index (SPI) at diffrent lead times and compare the solution with the benchmark models.\n",
    "\n",
    "- Implment baseline/benchmarks models:\n",
    "\n",
    "    - Persistence \n",
    "    - Climatology\n",
    "\n",
    "- Implement a baseline Convolutional Neural Network (CNN).\n",
    "\n",
    "- Perform hyperparameter tuning using \n",
    "   - GridSearch \n",
    "   - Random Search\n",
    "   - Hyperband\n",
    "   - Bayesian Optimization\n",
    "\n",
    "- Outperform the  baseline models.\n",
    "\n",
    "-  Compare the performance of the best model with the baseline models both statistically and using spatial plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Convolutional Neural Network (CNN)\n",
    "\n",
    "- is a class of neural networks that specializes in processing data that has a grid-like topology and generally composed of the following four layers. \n",
    "\n",
    "- These layers  are stacked together to form a deep neural network: input layer, convolutional layer, a pooling layer, and a fully connected layer.\n",
    "\n",
    "- **Input  Layer**: This is the first layer of the network where the input data is fed into the network.\n",
    "\n",
    "- **Convolution layer (CONV)** uses filters/kernals/learnable parameters that perform convolution operations as it is scanning on the input data to extract feature map or activation map. This layer performs a dot product between the two matrices.\n",
    "\n",
    "    - **Filter**: A filter is a small matrix that slides over the input data to extract features. \n",
    "\n",
    "    - **Stride**: The stride is the number of pixels the filter moves at a time.\n",
    "\n",
    "    - **Padding**:  Padding is the process of adding zeros around the input data to ensure that the output size is the same. Types of padding are Same, Full and Valid.\n",
    "    \n",
    "    - **Activation Functions**: These functions are used to introduce non-linearity in the model. Some of the activatation  functions used in CNN are ReLU, Leaky ReLU, ELU, Sigmoid, and Tanh.\n",
    "\n",
    "- **Pooling Layers**: These layers downsample the feature maps to reduce the spatial dimensions so its a downsampling operation.  This is done to reduce the number of parameters and computation in the network.  \n",
    "    \n",
    "    - There are two types of pooling layers: Max Pooling and Average Pooling.\n",
    "\n",
    "    -  **Max Pooling**: This is the most commonly used pooling layer. It selects the maximum value from each window of the feature map.\n",
    "\n",
    "    -  **Average Pooling**: This pooling layer calculates the average value of each window of the feature map.\n",
    "\n",
    "    \n",
    "- **Flattend  Layer**: This layer is used to flatten the output of the convolutional and pooling layers into a one -dimensional vector.\n",
    "\n",
    "- **Fully Connected Layers**: Operates on a flattened input where each input is connected to all neurons. These layers are used for classification or regression tasks.\n",
    "\n",
    "- **Out Put Layer**: This is the final layer of the network where the output is generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Image.open('image/CNN1.jpeg')\n",
    "display(cnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = Image.open('image/cnn1.png')\n",
    "display(cnn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load python packages   \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Masking, Conv2D, Flatten, Dense, Input, Activation\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\dl_drought\\deep-learning-drought-prediction\n"
     ]
    }
   ],
   "source": [
    "desired_directory = \"d:\\\\dl_drought\\\\deep-learning-drought-prediction\"\n",
    "os.chdir(desired_directory)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized Precipitation Index (SPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- is a widely used index to characterize meteorological drought by measuring precipitation over a specific time scale.\n",
    "\n",
    "- calculated by comparing the precipitation over a given time period (e.g., 1 month, 3 months) to the historical average for that same period, and expressing it as a standard deviation from the historical mean.\n",
    "\n",
    "- It is typically used to monitor short-term droughts or excessive wetness, and is sensitive to rapid changes in precipitation. \n",
    "\n",
    "- This index is helpful for assessing short-term impacts, such as on agriculture or soil moisture conditions.\n",
    "\n",
    "- Interpretation of SPI Values:\n",
    "\n",
    "    - Positive SPI: Indicates above-average precipitation (wetter conditions).\n",
    "\n",
    "    - Negative SPI: Indicates below-average precipitation (drier conditions or drought).\n",
    "\n",
    "\n",
    "- SPI values typically range from +2 to -2, where:\n",
    "\n",
    "    - SPI > 2: Extremely wet.\n",
    "    - SPI between 1.5 and 2: Very wet.\n",
    "    - SPI between 1 and 1.5: Moderately wet.\n",
    "    - SPI between -1 and -1.5: Moderately dry.\n",
    "    - SPI between -1.5 and -2: Very dry.\n",
    "    - SPI < -2: Extremely dry (drought conditions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPI-1 for 1981-Jan \n",
    "\n",
    "Historical drought years:\n",
    "\n",
    "| Years       | Regions                                                                 |\n",
    "|-------------|-------------------------------------------------------------------------|\n",
    "| 1983–1984   | All regions, particularly Tigray and Wollo                              |\n",
    "| 1987–1988   | All regions                                                             |\n",
    "| 1990–1992   | North, East, and South Ethiopia                                         |\n",
    "| 1993–1994   | Tigray and Wollo                                                        |\n",
    "| 2000        | All regions                                                             |\n",
    "| 2002–2003   | North, East, and Central Ethiopia                                       |\n",
    "| 2006        | The Southern Nations, Nationalities, and Peoples' Region (SNNPR) (Borena)|\n",
    "| 2008–2009   | North, East, Central, and South Ethiopia                                |\n",
    "| 2010–2011   | South-central, Southeastern, and Eastern parts of Ethiopia              |\n",
    "| 2015–2016   | Oromia, Somali, Amhara, Afar, Tigray, SNNPR                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SPI-3 Data\n",
    "\n",
    "- 1-month SPI represents the precipitation anomalies over a 1-month period, standardized relative to the long-term historical average of the same month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 15MB\n",
       "Dimensions:  (time: 504, lat: 56, lon: 68)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 4kB 1981-01-16 ... 2022-12-16\n",
       "  * lat      (lat) float32 224B 2.125 2.375 2.625 2.875 ... 15.38 15.62 15.88\n",
       "  * lon      (lon) float32 272B 32.12 32.38 32.62 32.88 ... 48.38 48.62 48.88\n",
       "Data variables:\n",
       "    spi      (time, lat, lon) float64 15MB ...\n",
       "Attributes:\n",
       "    creation_date:  Sun Sep 24 06:33:41 PM EAT 2023\n",
       "    Conventions:    None\n",
       "    source_file:    chrips_modfied_1981_2022.nc\n",
       "    title:          SPI</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-73162433-a0f1-4af2-a8fc-45ab8466952e' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-73162433-a0f1-4af2-a8fc-45ab8466952e' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 504</li><li><span class='xr-has-index'>lat</span>: 56</li><li><span class='xr-has-index'>lon</span>: 68</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-51002618-466f-4b19-8ce4-e2b38e74057f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-51002618-466f-4b19-8ce4-e2b38e74057f' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1981-01-16 ... 2022-12-16</div><input id='attrs-55cba4c2-7f8c-4991-893b-e0c708f1eaaa' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-55cba4c2-7f8c-4991-893b-e0c708f1eaaa' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bb1e614e-86d9-428a-a02c-f9725988a855' class='xr-var-data-in' type='checkbox'><label for='data-bb1e614e-86d9-428a-a02c-f9725988a855' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>T</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>standard_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1981-01-16T00:00:00.000000000&#x27;, &#x27;1981-02-14T12:00:00.000000000&#x27;,\n",
       "       &#x27;1981-03-16T00:00:00.000000000&#x27;, ..., &#x27;2022-10-16T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-11-15T12:00:00.000000000&#x27;, &#x27;2022-12-16T00:00:00.000000000&#x27;],\n",
       "      shape=(504,), dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>2.125 2.375 2.625 ... 15.62 15.88</div><input id='attrs-67e8a0b1-63f4-411d-8b3b-2588afcd5c9c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-67e8a0b1-63f4-411d-8b3b-2588afcd5c9c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-28786d4b-e3ac-4053-9d97-ce92cb23dcf0' class='xr-var-data-in' type='checkbox'><label for='data-28786d4b-e3ac-4053-9d97-ce92cb23dcf0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>Y</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([ 2.125,  2.375,  2.625,  2.875,  3.125,  3.375,  3.625,  3.875,  4.125,\n",
       "        4.375,  4.625,  4.875,  5.125,  5.375,  5.625,  5.875,  6.125,  6.375,\n",
       "        6.625,  6.875,  7.125,  7.375,  7.625,  7.875,  8.125,  8.375,  8.625,\n",
       "        8.875,  9.125,  9.375,  9.625,  9.875, 10.125, 10.375, 10.625, 10.875,\n",
       "       11.125, 11.375, 11.625, 11.875, 12.125, 12.375, 12.625, 12.875, 13.125,\n",
       "       13.375, 13.625, 13.875, 14.125, 14.375, 14.625, 14.875, 15.125, 15.375,\n",
       "       15.625, 15.875], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>32.12 32.38 32.62 ... 48.62 48.88</div><input id='attrs-86a75331-3916-498e-af14-9371e71348a5' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-86a75331-3916-498e-af14-9371e71348a5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-18f72237-9a50-4a08-9e18-7a082384e0fd' class='xr-var-data-in' type='checkbox'><label for='data-18f72237-9a50-4a08-9e18-7a082384e0fd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>axis :</span></dt><dd>X</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([32.125, 32.375, 32.625, 32.875, 33.125, 33.375, 33.625, 33.875, 34.125,\n",
       "       34.375, 34.625, 34.875, 35.125, 35.375, 35.625, 35.875, 36.125, 36.375,\n",
       "       36.625, 36.875, 37.125, 37.375, 37.625, 37.875, 38.125, 38.375, 38.625,\n",
       "       38.875, 39.125, 39.375, 39.625, 39.875, 40.125, 40.375, 40.625, 40.875,\n",
       "       41.125, 41.375, 41.625, 41.875, 42.125, 42.375, 42.625, 42.875, 43.125,\n",
       "       43.375, 43.625, 43.875, 44.125, 44.375, 44.625, 44.875, 45.125, 45.375,\n",
       "       45.625, 45.875, 46.125, 46.375, 46.625, 46.875, 47.125, 47.375, 47.625,\n",
       "       47.875, 48.125, 48.375, 48.625, 48.875], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6cafc585-0750-4dab-94a0-68f410683416' class='xr-section-summary-in' type='checkbox'  checked><label for='section-6cafc585-0750-4dab-94a0-68f410683416' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>spi</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-55dffe21-11cb-44ba-bd77-f7327856d45d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-55dffe21-11cb-44ba-bd77-f7327856d45d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-47889a40-b6c8-4d4e-a269-e48a67cd51ff' class='xr-var-data-in' type='checkbox'><label for='data-47889a40-b6c8-4d4e-a269-e48a67cd51ff' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>run=3</dd><dt><span>long_name :</span></dt><dd>SPI</dd></dl></div><div class='xr-var-data'><pre>[1919232 values with dtype=float64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2d5e4b2b-77c3-4514-a685-f68ce56494ca' class='xr-section-summary-in' type='checkbox'  ><label for='section-2d5e4b2b-77c3-4514-a685-f68ce56494ca' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-ad091b10-612a-4261-9bb1-ce21206f74eb' class='xr-index-data-in' type='checkbox'/><label for='index-ad091b10-612a-4261-9bb1-ce21206f74eb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1981-01-16 00:00:00&#x27;, &#x27;1981-02-14 12:00:00&#x27;,\n",
       "               &#x27;1981-03-16 00:00:00&#x27;, &#x27;1981-04-15 12:00:00&#x27;,\n",
       "               &#x27;1981-05-16 00:00:00&#x27;, &#x27;1981-06-15 12:00:00&#x27;,\n",
       "               &#x27;1981-07-16 00:00:00&#x27;, &#x27;1981-08-16 00:00:00&#x27;,\n",
       "               &#x27;1981-09-15 12:00:00&#x27;, &#x27;1981-10-16 00:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2022-03-16 00:00:00&#x27;, &#x27;2022-04-15 12:00:00&#x27;,\n",
       "               &#x27;2022-05-16 00:00:00&#x27;, &#x27;2022-06-15 12:00:00&#x27;,\n",
       "               &#x27;2022-07-16 00:00:00&#x27;, &#x27;2022-08-16 00:00:00&#x27;,\n",
       "               &#x27;2022-09-15 12:00:00&#x27;, &#x27;2022-10-16 00:00:00&#x27;,\n",
       "               &#x27;2022-11-15 12:00:00&#x27;, &#x27;2022-12-16 00:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=504, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-74b8de02-b69d-4df0-9719-d92f97652d55' class='xr-index-data-in' type='checkbox'/><label for='index-74b8de02-b69d-4df0-9719-d92f97652d55' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 2.125,  2.375,  2.625,  2.875,  3.125,  3.375,  3.625,  3.875,  4.125,\n",
       "        4.375,  4.625,  4.875,  5.125,  5.375,  5.625,  5.875,  6.125,  6.375,\n",
       "        6.625,  6.875,  7.125,  7.375,  7.625,  7.875,  8.125,  8.375,  8.625,\n",
       "        8.875,  9.125,  9.375,  9.625,  9.875, 10.125, 10.375, 10.625, 10.875,\n",
       "       11.125, 11.375, 11.625, 11.875, 12.125, 12.375, 12.625, 12.875, 13.125,\n",
       "       13.375, 13.625, 13.875, 14.125, 14.375, 14.625, 14.875, 15.125, 15.375,\n",
       "       15.625, 15.875],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-4a8d5bb3-30c3-4f96-8bf3-de9e32e509cd' class='xr-index-data-in' type='checkbox'/><label for='index-4a8d5bb3-30c3-4f96-8bf3-de9e32e509cd' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([32.125, 32.375, 32.625, 32.875, 33.125, 33.375, 33.625, 33.875, 34.125,\n",
       "       34.375, 34.625, 34.875, 35.125, 35.375, 35.625, 35.875, 36.125, 36.375,\n",
       "       36.625, 36.875, 37.125, 37.375, 37.625, 37.875, 38.125, 38.375, 38.625,\n",
       "       38.875, 39.125, 39.375, 39.625, 39.875, 40.125, 40.375, 40.625, 40.875,\n",
       "       41.125, 41.375, 41.625, 41.875, 42.125, 42.375, 42.625, 42.875, 43.125,\n",
       "       43.375, 43.625, 43.875, 44.125, 44.375, 44.625, 44.875, 45.125, 45.375,\n",
       "       45.625, 45.875, 46.125, 46.375, 46.625, 46.875, 47.125, 47.375, 47.625,\n",
       "       47.875, 48.125, 48.375, 48.625, 48.875],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lon&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b92307d7-a027-47ab-a981-cf7891484c77' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b92307d7-a027-47ab-a981-cf7891484c77' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>creation_date :</span></dt><dd>Sun Sep 24 06:33:41 PM EAT 2023</dd><dt><span>Conventions :</span></dt><dd>None</dd><dt><span>source_file :</span></dt><dd>chrips_modfied_1981_2022.nc</dd><dt><span>title :</span></dt><dd>SPI</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 15MB\n",
       "Dimensions:  (time: 504, lat: 56, lon: 68)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 4kB 1981-01-16 ... 2022-12-16\n",
       "  * lat      (lat) float32 224B 2.125 2.375 2.625 2.875 ... 15.38 15.62 15.88\n",
       "  * lon      (lon) float32 272B 32.12 32.38 32.62 32.88 ... 48.38 48.62 48.88\n",
       "Data variables:\n",
       "    spi      (time, lat, lon) float64 15MB ...\n",
       "Attributes:\n",
       "    creation_date:  Sun Sep 24 06:33:41 PM EAT 2023\n",
       "    Conventions:    None\n",
       "    source_file:    chrips_modfied_1981_2022.nc\n",
       "    title:          SPI"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spi3_1981_2022 = xr.open_dataset('data/processed/SPI_Computed/chrips_spi3_1981_2022.nc') \n",
    "spi3_1981_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi3_1981_2022.spi[2,:,:].plot( cmap='coolwarm_r')\n",
    "# plt.title('SPI-3 for January of the year 1981')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the time dimension into standared datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi3_1981_2022['time'] = pd.date_range(start='1/1/1981', periods=spi3_1981_2022.sizes['time'], freq='ME')\n",
    "spi3_1981_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPI-3: January - December of the year 2000\n",
    "\n",
    "According to USAID, GFDRE,  Famine Early Warning System reports:\n",
    "\n",
    "- ~ 8 million people are affected by the drought.\n",
    "\n",
    "- total failure of the 1999 belg rains.\n",
    "\n",
    "- primarily in the southern and southeastern portions of the country.\n",
    "\n",
    "- mainly due to the failure of the secondary harvest, or belg season, this number may increase to as many as 10 million people to include northern drought-affected regions (the highlands) of the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(28, 18))\n",
    "for i in range(1, 13):\n",
    "    last_day = calendar.monthrange(2000, i)[1]  \n",
    "    date_str = f'2000-{str(i).zfill(2)}-{last_day}'\n",
    "    spi3_1981_2022.sel(time=date_str).spi.plot(ax=axs.flat[i-1], cmap='coolwarm_r')\n",
    "    axs.flat[i-1].set_title(f'SPI-3 for {str(i).zfill(2)}-2000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPI-3: January - December of the year 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to USAID, GFDRE,  Famine Early Warning System reports:\n",
    "\n",
    " - North and central/eastern Ethiopia has experienced the worst drought in more than 50 years\n",
    "\n",
    " - The drought affected nearly 10 million Ethiopians.\n",
    "\n",
    " - In 2015, after a false start, the belg rains came a month late in northern and central Ethiopia and kiremt season was delayed and the rains were erratic and below average. \n",
    "\n",
    " -  February to May Belg rains were erratic and well below average; and the subsequent June to September Kinemt rains started late and were also significantly below average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(28, 16))\n",
    "for i in range(1, 13):\n",
    "    last_day = calendar.monthrange(2015, i)[1]  \n",
    "    date_str = f'2015-{str(i).zfill(2)}-{last_day}'\n",
    "    spi3_1981_2022.sel(time=date_str).spi.plot(ax=axs.flat[i-1], cmap='coolwarm_r')\n",
    "    axs.flat[i-1].set_title(f'SPI-3 for {str(i).zfill(2)}-2015')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewa_report2015 = Image.open('image/fews_report.png')\n",
    "display(fewa_report2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_regimes = 'rainfall_ragiem/rainfall_ragiem.shp'\n",
    "\n",
    "et_rainfall_regimes = gpd.read_file(et_regimes)\n",
    "\n",
    "et_rainfall_regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of new region names\n",
    "new_region_names = ['RegionA', \n",
    "                    'RegionB', \n",
    "                    'RegionC', \n",
    "                    'RegionD', \n",
    "                    'RegionE', \n",
    "                    'RegionF', \n",
    "                    'RegionG', \n",
    "                    'RegionH']\n",
    "\n",
    "# Add the new column to the GeoDataFrame\n",
    "et_rainfall_regimes['Region'] = new_region_names\n",
    "\n",
    "# Print the updated GeoDataFrame\n",
    "et_rainfall_regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot each GeoDataFrame on the same axis\n",
    "et_rainfall_regimes.plot(ax=ax, cmap ='jet',\n",
    "                         linewidth=1,\n",
    "                         zorder=1,\n",
    "                         edgecolor='black',\n",
    "                         linestyle='-')\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Ethiopian Rainfall Regimes')\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "# plt.savefig('East_africa_region.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegionA = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionA\"]\n",
    "RegionB = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionB\"]\n",
    "RegionC = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionC\"]\n",
    "RegionD = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionD\"]\n",
    "RegionE = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionE\"]\n",
    "RegionF = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionF\"]\n",
    "RegionG = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionG\"]\n",
    "RegionH = et_rainfall_regimes.loc[et_rainfall_regimes.Region == \"RegionH\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset the dataset\n",
    "\n",
    "  - Centran Ethiopia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi3_1981_2022_sub = spi3_1981_2022.sel(lat=slice(7,11), lon=slice(37,40.5))\n",
    "spi3_1981_2022_sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the subset the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(28, 16))\n",
    "for i in range(1, 13):\n",
    "    last_day = calendar.monthrange(2015, i)[1]  \n",
    "    date_str = f'2015-{str(i).zfill(2)}-{last_day}'\n",
    "    spi3_1981_2022_sub.sel(time=date_str).spi.plot(ax=axs.flat[i-1], cmap='coolwarm_r')\n",
    "\n",
    "    axs.flat[i-1].set_title(f'SPI-3 for {str(i).zfill(2)}-2015')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the RegionD GeoDataFrame\n",
    "region_d_gdf = et_rainfall_regimes[et_rainfall_regimes['Region'] == 'RegionD']\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(3, 4, figsize=(28, 16))\n",
    "\n",
    "for i in range(1, 13):\n",
    "    last_day = calendar.monthrange(2015, i)[1]\n",
    "    date_str = f'2015-{str(i).zfill(2)}-{last_day}'\n",
    "    \n",
    "    # Plot the SPI data\n",
    "    spi3_1981_2022_sub.sel(time=date_str).spi.plot(ax=axs.flat[i-1], cmap='coolwarm_r')\n",
    "    \n",
    "    # Overlay the RegionD GeoDataFrame\n",
    "    region_d_gdf.plot(ax=axs.flat[i-1], edgecolor='black', facecolor='none')\n",
    "    \n",
    "    # Set the title\n",
    "    axs.flat[i-1].set_title(f'SPI-3 for {str(i).zfill(2)}-2015')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset selection\n",
    "train_years = slice('1981', '2012')\n",
    "# validation dataset selection (this dataset helps with overfitting)\n",
    "valid_years = slice('2013', '2018')\n",
    "# test dataset selection\n",
    "test_years = slice('2019', '2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years, valid_years, test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_range = slice('1981-01-01', '2013-01-01')\n",
    "valid_time_range = slice('2013-01-01', '2019-01-01')\n",
    "test_time_range = slice('2019-01-01', '2023-01-01')\n",
    "\n",
    "train_time_range, valid_time_range, test_time_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the percentage of the data used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string dates to datetime objects\n",
    "train_start = datetime.strptime(train_time_range.start, '%Y-%m-%d')\n",
    "train_stop = datetime.strptime(train_time_range.stop, '%Y-%m-%d')\n",
    "valid_start = datetime.strptime(valid_time_range.start, '%Y-%m-%d')\n",
    "valid_stop = datetime.strptime(valid_time_range.stop, '%Y-%m-%d')\n",
    "test_start = datetime.strptime(test_time_range.start, '%Y-%m-%d')\n",
    "test_stop = datetime.strptime(test_time_range.stop, '%Y-%m-%d')\n",
    "\n",
    "# Calculate the percentage of the data used\n",
    "train_percentage = (train_stop - train_start).days / (test_stop - train_start).days\n",
    "valid_percentage = (valid_stop - valid_start).days / (test_stop - train_start).days\n",
    "test_percentage = (test_stop - test_start).days / (test_stop - train_start).days\n",
    "\n",
    "print (f'Training data: {train_percentage:.2%}')\n",
    "print (f'Validation data: {valid_percentage:.2%}')\n",
    "print (f'Test data: {test_percentage:.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of years in each dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of years used for training, validation, and testing\n",
    "train_year = (train_stop - train_start).days / 365.25\n",
    "valid_year = (valid_stop - valid_start).days / 365.25\n",
    "test_year = (test_stop - test_start).days / 365.25\n",
    "\n",
    "# Print the number of years used for training, validation, and testing\n",
    "\n",
    "print(f'Training years: {train_year:.1f}')\n",
    "print(f'Validation years: {valid_year:.1f}')\n",
    "print(f'Test years: {test_year:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute benchmark/baselines\n",
    "\n",
    "- Persistence Model\n",
    "- Climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implment Persistence Forecast\n",
    "\n",
    "- a simple forecasting method that assumes the current conditions will persist into the future.\n",
    "\n",
    "- Persistence simply means: Tomorrow's weather is today's weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lead time steps (e.g., 1 month)\n",
    "\n",
    "lead_time_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data along the time dimension by 'lead_time_steps'\n",
    "shifted_data1 = spi3_1981_2022_sub.shift(time=lead_time_steps)\n",
    "shifted_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the NAN created when shifting the data\n",
    "\n",
    "shifted_data1_cliped = shifted_data1.isel(time=slice(2+lead_time_steps, None))\n",
    "shifted_data1_cliped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the values before and after shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data before shifting\n",
    "spi3_1981_2022_sub.spi[2, :, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data after shifting\n",
    "shifted_data1.spi[3, :, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent forecast for 1 month ahead\n",
    "persit_fc = shifted_data1_cliped.sel(time=test_years)\n",
    "persit_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target data\n",
    "gt_test = spi3_1981_2022_sub.sel(time=test_years)\n",
    "gt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make subplot of the forecast and target data\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "persit_fc.spi[0, :, :].plot(ax=ax[0])\n",
    "gt_test.spi[0, :, :].plot(ax=ax[1])\n",
    "\n",
    "# ax[0].set_title('Forecast')\n",
    "# ax[1].set_title('Target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area weighted Root Mean Square Error (RMSE) for persistence model\n",
    "\n",
    "- calculates the weighted root mean squared error (RMSE) between a forecast (fc) and ground truth (gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the difference between the predicted values and the actual values\n",
    "error = persit_fc - gt_test\n",
    "\n",
    "# computes the weighted RMSE\n",
    "weights_lat = np.cos(np.deg2rad(error.lat))\n",
    "\n",
    "# Normalize the weights\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_persit = np.sqrt(((error)**2 * weights_lat).mean(('time', 'lat', 'lon')))\n",
    "\n",
    "# Print the RMSE value\n",
    "rmse_persit = rmse_persit.spi.values\n",
    "\n",
    "rmse_persit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implment Climatology Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Climatology is calculated for each month of year from the training time period\n",
    "\n",
    "- Training time period (1981 to 2011) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The climatology is calculated for each month of the year from the training time period\n",
    "clim_mon = spi3_1981_2022_sub.sel(time=train_years).groupby('time.month').mean()\n",
    "clim_mon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the climatology for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the climatology for each month of the year\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(28, 16))\n",
    "\n",
    "for i in range(1, 13):\n",
    "    clim_mon.sel(month=i).spi.plot(ax=axs.flat[i-1], cmap='coolwarm_r')\n",
    "    axs.flat[i-1].set_title(f'Climatology for {calendar.month_abbr[i]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assingn the the climatology for the corresponding months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the test years from the dataset\n",
    "test_years_data = spi3_1981_2022.sel(time=test_years)\n",
    "\n",
    "# Extract the month from the time dimension\n",
    "test_years_months = test_years_data.time.dt.month\n",
    "\n",
    "# Select the climatology for the corresponding months\n",
    "clim_monthly_selected = clim_mon.sel(month=test_years_months)\n",
    "\n",
    "clim_monthly_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area weighted Root Mean Square Error (RMSE) for the climatology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_pre  = clim_monthly_selected\n",
    "\n",
    "# calculates the difference between the predicted values and the actual values\n",
    "error = clim_pre - gt_test\n",
    "\n",
    "# computes the weighted RMSE\n",
    "weights_lat = np.cos(np.deg2rad(error.lat))\n",
    "\n",
    "# Normalize the weights\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_clim = np.sqrt(((error)**2 * weights_lat).mean(('time', 'lat', 'lon')))\n",
    "\n",
    "# Print the RMSE value\n",
    "rmse_clim = rmse_clim.spi.values\n",
    "\n",
    "rmse_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implment CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method1 = Image.open('image/cnn_clim.png')\n",
    "display(method1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train, validation, and test data\n",
    "train_data = spi3_1981_2022_sub.sel(time=train_years)\n",
    "valid_data = spi3_1981_2022_sub.sel(time=valid_years)\n",
    "test_data = spi3_1981_2022_sub.sel(time=test_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "mean = train_data.mean()\n",
    "std = train_data.std()\n",
    "\n",
    "# Print the mean and standard deviation and round to 2 decimal places\n",
    "print(f\"Mean: {mean.spi.values.round(2)}\")\n",
    "print(f\"Standard deviation: {std.spi.values.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "valid_data = (valid_data - mean) / std\n",
    "test_data = (test_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_steps = lead_time_steps\n",
    "lead_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a feature and target datasets\n",
    "\n",
    "- From the input data prepare X and Y data \n",
    "- Input data format for CNN model\n",
    "\n",
    "    - number of netcdf/images\n",
    "    - number of lon  (image width)\n",
    "    - number of lat (image height)\n",
    "    - number of color channels ( e.g., 3 for RGB), features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since its SPI-3, we remove the first two months of the year\n",
    "train_data_spi3 = train_data.isel(time=slice(2, None))\n",
    "train_data_spi3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target  variable selection for trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dat from the beginning except for the last lead_steps elements.\n",
    "# add a \"channel\" or \"feature\" axis to the data to make it compatible with the CNN\n",
    "\n",
    "\n",
    "# ------------------\n",
    "#   X          Y\n",
    "# 1981-03  1981-04\n",
    "# 1981-02  1981-05\n",
    "# -------------------\n",
    "\n",
    "X_train = train_data_spi3.spi.isel(time=slice(None, -lead_steps)).values[..., None]\n",
    "\n",
    "# Subset the data from the beginning starting from the lead_steps elements to the end\n",
    "Y_train = train_data_spi3.spi.isel(time=slice(lead_steps, None)).values[..., None]\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target  variable selection for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid_data.spi.isel(time=slice(None, -lead_steps)).values[..., None]\n",
    "Y_valid = valid_data.spi.isel(time=slice(lead_steps, None)).values[..., None]\n",
    "X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target  variable selection for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.spi.isel(time=slice(None, -lead_steps)).values[..., None]\n",
    "Y_test = test_data.spi.isel(time=slice(lead_steps, None)).values[..., None]\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Definition \n",
    "\n",
    "-  Layer 1: 2D convolutional (Conv2D) layer with the following parameters:\n",
    "    - 32 filters, kernels, feature detectors\n",
    "    - 2x2 kernel size \n",
    "    - padding='same', which means that the output will have the same spatial dimensions as the input, with the padding being added to the input data to achieve this.\n",
    "\n",
    "- Layer 2:Exponential Linear Unit (ELU) activation function\n",
    "\n",
    "- Layer 3: Conv2D\n",
    "\n",
    "    - 32 filters\n",
    "    - 2x2 kernel size\n",
    "    -padding='same'\n",
    "\n",
    "- Layer 4: Another ELU activation function.\n",
    "\n",
    "- Layer 5: Conv2D \n",
    "\n",
    "    - 1 filter (i.e., a single feature map is output)\n",
    "    - 2x2 kernel size\n",
    "    - padding='same'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape based on the first 32 samples of X_train\n",
    "input_shape = X_train[:32].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first Conv2D layer with 32 filters, kernel size of 5, and 'same' padding\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', activation='tanh'))\n",
    "\n",
    "# Add the second Conv2D layer with 32 filters, kernel size of 5, and 'same' padding\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', activation='tanh'))\n",
    "\n",
    "# Add the final Conv2D layer with 1 filter, kernel size of 5, and 'same' padding\n",
    "model.add(Conv2D(1, kernel_size=3, padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the specified input shape\n",
    "model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the Adam optimizer with the specified learning rate\n",
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model with the Adam optimizer and mean squared error loss function\n",
    "model.compile(optimizer=adam_optimizer, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=10,         # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data with early stopping\n",
    "history = model.fit(\n",
    "    X_train,  # Input features\n",
    "    Y_train,  # Target values\n",
    "    batch_size=32,  # Number of samples per gradient update\n",
    "    epochs=20,  # Number of epochs to train the model\n",
    "    verbose=1,  # Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "    validation_data=(X_valid, Y_valid),  # Validation data\n",
    "    callbacks=[early_stopping]  # List of callbacks to apply during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model on the training data\n",
    "# history = model.fit(\n",
    "#     X_train,  # Input features\n",
    "#     Y_train,  # Target values\n",
    "#     batch_size=32,  # Number of samples per gradient update\n",
    "#     epochs=300,  # Number of epochs to train the model\n",
    "#     verbose=1,  # Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "#     validation_data=(X_valid, Y_valid)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = X_train[:, :, :, 0].copy()\n",
    "pred_train[:] = model.predict(X_train).squeeze()\n",
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for the validation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_valid = X_valid[:, :, :, 0].copy()\n",
    "pred_valid[:] = model.predict(X_valid).squeeze()\n",
    "pred_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the first channel of X_test and remove the channel axis\n",
    "# So that it will have the shape (time, lat, lon) as the  xarray format \n",
    "pred_test = X_test[:, :, :, 0].copy()\n",
    "\n",
    "# Predict the output using the model and update pred_test\n",
    "pred_test[:] = model.predict(X_test).squeeze()\n",
    "\n",
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean and std values\n",
    "\n",
    "mean_val = mean.spi.values\n",
    "std_val = std.spi.values\n",
    "\n",
    "# Scale the predictions by multiplying with the standard deviation and adding the mean\n",
    "pred_train = pred_train * std_val + mean_val\n",
    "pred_valid = pred_valid * std_val + mean_val\n",
    "pred_test = pred_test * std_val + mean_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area weighted Root Mean Square Error (RMSE) of CNN  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test data the xarray format for test period \n",
    "target = spi3_1981_2022_sub.sel(time=test_years)['spi']\n",
    "y_test = target.isel(time=slice(lead_time_steps, None))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the difference between the predicted values and the actual values\n",
    "error = pred_test - y_test\n",
    "\n",
    "# computes the weighted RMSE\n",
    "weights_lat = np.cos(np.deg2rad(error.lat))\n",
    "\n",
    "# Normalize the weights\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_cnn = np.sqrt(((error)**2 * weights_lat).mean(('time', 'lat', 'lon')))\n",
    "\n",
    "# Print the RMSE value\n",
    "rmse_cnn = rmse_cnn.values\n",
    "rmse_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapare the RMSE results for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Persistence': rmse_persit.round(2),\n",
    "    'Climatology': rmse_clim.round(2),\n",
    "    'CNN': rmse_cnn.round(2)\n",
    "}\n",
    "\n",
    "results\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "\n",
    "results_df = pd.DataFrame(results, index=['RMSE'])\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for train and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Train and validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Trainning loss', 'Validation loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot for train and validation mse\n",
    "\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Train and validation val_accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Trainning accuracy', 'Validation accuracy'], loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contesnts of history.history\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hyperparameter \n",
    "\n",
    "- KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search. \n",
    "\n",
    "    - Grid Search\n",
    "    - Random  Search\n",
    "    - Bayesian Optimization\n",
    "    - Hyperband\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameters = {\n",
    "    'num_filters': [32, 64, 128, 256],\n",
    "    'kernel_size': [2, 3, 5],\n",
    "    'activation': ['elu', 'relu', 'tanh' ],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 50, 100, 150, 200, 250, 300, 350]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the build_model function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hp.Int('num_filters', min_value=32, max_value=256, step=32), \n",
    "                     kernel_size=hp.Int('kernel_size', min_value=2, max_value=5, step=1), \n",
    "                     padding='same', \n",
    "                     activation=hp.Choice('activation', values=['elu', 'relu', 'tanh'])))\n",
    "    model.add(Conv2D(hp.Int('num_filters', min_value=32, max_value=256, step=32), \n",
    "                     kernel_size=hp.Int('kernel_size', min_value=2, max_value=5, step=1), \n",
    "                     padding='same', \n",
    "                     activation=hp.Choice('activation', values=['elu', 'relu', 'tanh'])))\n",
    "    model.add(Conv2D(1, kernel_size=hp.Int('kernel_size', min_value=2, max_value=5, step=1), padding='same'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tuner instance\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Define the objective as a string\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_valid, Y_valid, epochs=10, validation_data=(X_test, Y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = tuner.results_summary()\n",
    "\n",
    "# Check if best_metrics is not None\n",
    "if best_metrics is not None:\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    print(best_hyperparameters.values)\n",
    "    print(\"Best Validation Loss:\", best_metrics.iloc[0]['val_loss'])\n",
    "else:\n",
    "    print(\"Error: Unable to retrieve best metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Hyperparameter Method': ['Grid Search', 'Random Search', 'Hyperband', 'Bayesian Optimization'],\n",
    "    'Best Val Loss': [0.4397370219230652, 0.43754181265830994, 0.4509032368659973, 0.43088677525520325],\n",
    "    'num_filters': [32, 160, 128, 96],\n",
    "    'kernel_size': [2, 2, 3, 4],\n",
    "    'Activation': ['tanh', 'elu', 'tanh', 'tanh']\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth, Persistence, Climatology & CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xarray = spi3_1981_2022_sub.spi.sel(time=test_years).isel(time=slice(lead_time_steps, None)).copy()\n",
    "pred_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the data array with the predicted values\n",
    "pred_xarray.data = pred_test\n",
    "pred_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid_xarray = spi3_1981_2022_sub.spi.sel(time=valid_years).isel(time=slice(lead_time_steps, None)).copy()\n",
    "pred_valid_xarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid_xarray.data = pred_valid\n",
    "pred_valid_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_xarray = train_data_spi3.spi.sel(time=train_years).isel(time=slice(lead_time_steps, None)).copy()\n",
    "pred_train_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_xarray.data = pred_train\n",
    "pred_train_xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Ground Truth, Persistence, Climatology & CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the RegionD GeoDataFrame\n",
    "region_d_gdf = et_rainfall_regimes[et_rainfall_regimes['Region'] == 'RegionD']\n",
    "\n",
    "# Select a specific month from the test data\n",
    "selected_month = '2002-07-31'  # Example: April 2019\n",
    "\n",
    "\n",
    "# Train: 1981 - 2012\n",
    "# Valid: 2013 - 2018\n",
    "# Test: 2019 - 2023\n",
    "\n",
    "# 01-31, 02-28, 03-31, 04-30, 05-31, 06-30, 07-31, 08-31, 09-30, 10-31, 11-30, 12-31\n",
    "\n",
    "# Create subplots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Plot ground truth for the selected month\n",
    "\n",
    "# # Plot the groud truth for the selected month of the test data\n",
    "# test_data.spi.sel(time=selected_month).plot(ax=ax1, cmap='coolwarm_r')\n",
    "# # Overlay the RegionD GeoDataFrame\n",
    "# region_d_gdf.plot(ax=ax1, edgecolor='black', facecolor='none')\n",
    "# ax1.set_title('Ground Truth')\n",
    "\n",
    "# Plot for the ground truth for the selected month of the validation \n",
    "# valid_data.spi.sel(time=selected_month).plot(ax=ax1, cmap='coolwarm_r')\n",
    "# # Overlay the RegionD GeoDataFrame\n",
    "# region_d_gdf.plot(ax=ax1, edgecolor='black', facecolor='none')\n",
    "# ax1.set_title('Ground Truth')\n",
    "\n",
    "# # Plot for the ground truth for the selected month of the train data \n",
    "train_data.spi.sel(time=selected_month).plot(ax=ax1, cmap='coolwarm_r')\n",
    "# Overlay the RegionD GeoDataFrame\n",
    "region_d_gdf.plot(ax=ax1, edgecolor='black', facecolor='none')\n",
    "ax1.set_title('Ground Truth')\n",
    "\n",
    "\n",
    "# Plot the persistence forecast for the selected month\n",
    "persit_fc.spi.sel(time=selected_month,  method='nearest').plot(ax=ax2, cmap='coolwarm_r')\n",
    "\n",
    "# Overlay the RegionD GeoDataFrame\n",
    "region_d_gdf.plot(ax=ax2, edgecolor='black', facecolor='none')\n",
    "ax2.set_title('Persistence Forecast')\n",
    "\n",
    "\n",
    "# Plot the climatology for the selected month\n",
    "clim_pre.spi.sel(time=selected_month,  method='nearest').plot(ax=ax3, cmap='coolwarm_r')\n",
    "# Overlay the RegionD GeoDataFrame\n",
    "region_d_gdf.plot(ax=ax3, edgecolor='black', facecolor='none')\n",
    "ax3.set_title('Climatology')\n",
    "\n",
    "\n",
    "# Plot the CNN forecast for the selected month\n",
    "# pred_xarray.sel(time=selected_month).plot(ax=ax4, cmap='coolwarm_r')\n",
    "# # Overlay the RegionD GeoDataFrame\n",
    "# region_d_gdf.plot(ax=ax4, edgecolor='black', facecolor='none')\n",
    "# ax4.set_title('CNN Forecast')\n",
    "\n",
    "\n",
    "# plot for the valid data for the selected month\n",
    "\n",
    "# pred_valid_xarray.sel(time=selected_month).plot(ax=ax4, cmap='coolwarm_r')\n",
    "# # Overlay the RegionD GeoDataFrame\n",
    "# region_d_gdf.plot(ax=ax4, edgecolor='black', facecolor='none')\n",
    "# ax4.set_title('CNN Forecast')\n",
    "\n",
    "# plot for the train data for the selected month\n",
    "\n",
    "pred_train_xarray.sel(time=selected_month).plot(ax=ax4, cmap='coolwarm_r')\n",
    "# Overlay the RegionD GeoDataFrame\n",
    "region_d_gdf.plot(ax=ax4, edgecolor='black', facecolor='none')\n",
    "ax4.set_title('CNN Forecast')\n",
    "\n",
    "\n",
    "# Title for the entire plot\n",
    "\n",
    "plt.suptitle(f' Predicted SPI at 1 month lead time for {selected_month}', fontsize=22)\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_drought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
